{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1Mj_ojzIbeY55oa2N7Z45ac0tNMPhLZB4","authorship_tag":"ABX9TyOntW48HfJw2j5mi73WLAet"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# bibliotecas usadas para manipulação do projeto\n"],"metadata":{"id":"zZMhMXMy4uOI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"5E63viJyU9-j","executionInfo":{"status":"error","timestamp":1755581383091,"user_tz":180,"elapsed":5958,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}},"outputId":"f6555c13-6d5d-4687-d5d9-2b03c4b9a0d7","colab":{"base_uri":"https://localhost:8080/","height":269}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1980224743.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_register_onnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .boxes import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbox_area\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbox_convert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/_register_onnx_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic_opset11\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopset11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_type_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJitScalarType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxExporterError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0m_run_symbolic_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_deprecation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_helper\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_globals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLOBALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiagnostics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_proto_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregistration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._diagnostic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcreate_export_diagnostic_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdiagnose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexport_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/_diagnostic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msarif_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/infra/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from ._infra import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDiagnosticOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mInvocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/infra/_infra.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/infra/formatter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msarif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/diagnostics/infra/sarif/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edge_traversal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdgeTraversal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msarif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from torch.onnx._internal.diagnostics.infra.sarif._external_properties import (\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import torchvision\n","import matplotlib.pyplot as plt\n","from time import time\n","from torchvision import datasets, transforms\n","from torch import nn, optim"]},{"cell_type":"markdown","source":["# Define a transformação para converter as imagens em tensores PyTorch\n","\n","## carregando imagens do MNIST e exibindo um exemplo de imagem para teste"],"metadata":{"id":"f8bWAQmH49UJ"}},{"cell_type":"code","source":["\n","transform = transforms.ToTensor()\n","\n","# Carrega o conjunto de dados de treinamento do MNIST\n","# Se os dados não estiverem presentes no caminho especificado, eles serão baixados.\n","# train=True especifica que queremos o conjunto de treinamento.\n","# transform=transform aplica a transformação definida acima aos dados.\n","trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n","# Cria um DataLoader para o conjunto de treinamento.\n","# Um DataLoader ajuda a carregar os dados em lotes (batches) para o treinamento.\n","# batch_size=64 define o número de amostras por lote.\n","# shuffle=True embaralha os dados a cada época para melhorar o treinamento.\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Carrega o conjunto de dados de validação do MNIST\n","# train=False especifica que queremos o conjunto de validação.\n","valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n","# Cria um DataLoader para o conjunto de validação com as mesmas configurações.\n","valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"],"metadata":{"id":"Le-O6Q66YZZE","executionInfo":{"status":"aborted","timestamp":1755581383133,"user_tz":180,"elapsed":30,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataiter = iter(trainloader)\n","imagens, etiquetas = dataiter.__next__()\n","\n","plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"],"metadata":{"id":"tHOl4ayzZ03t","executionInfo":{"status":"aborted","timestamp":1755581383137,"user_tz":180,"elapsed":15,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## imprimindo dimensões e etiquetas da imagm teste"],"metadata":{"id":"5EmWrqJM5stm"}},{"cell_type":"code","source":["print(imagens[0].shape)  # dimensões do tensor de cada imagem\n","print(etiquetas[0].shape)  # dimensões da etiqueta de cada imagem"],"metadata":{"id":"vX_Ex5dSazjX","executionInfo":{"status":"aborted","timestamp":1755581383142,"user_tz":180,"elapsed":18,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Definindo a estrutura do modelo usado na rede neural.\n","\n","[Keras InceptionV3](https://keras.io/api/applications/inceptionv3/)"],"metadata":{"id":"XpnsIY7x5_21"}},{"cell_type":"code","source":["class Modelo(nn.Module):\n","    def __init__(self):\n","        super(Modelo, self).__init__()\n","        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n","        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n","        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n","        # para a camada de saída não e necessário definir nada pois só precisamos pegar o output da camada interna 2\n","\n","    def forward(self, X):\n","        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n","        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n","        X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n","        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"],"metadata":{"id":"DunfUtN_d9Cx","executionInfo":{"status":"aborted","timestamp":1755581383145,"user_tz":180,"elapsed":19,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Definindo os parametros usados no modelo de treinamento"],"metadata":{"id":"g_ZFQzCE6nMh"}},{"cell_type":"code","source":["def treino(modelo, trainloader, device):\n","\n","    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a polítca de atualização dos peso\n","    inicio = time() # timer para sabermos quanto tempo levou o treino\n","\n","    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n","    EPOCHS = 10 # numero de epochs que o algoritmo rodará\n","    modelo.train() # ativando o modo de treinamento do modelo\n","\n","    for epoch in range(EPOCHS):\n","        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n","\n","        for imagens, etiquetas in trainloader:\n","\n","            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas\n","            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n","\n","            output = modelo(imagens.to(device)) # colocando os dados no modelo\n","            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n","\n","            perda_instantanea.backward() # back propagation a partir da perda\n","\n","            otimizador.step() # atualizando os pesos e a bias\n","\n","            perda_acumulada += perda_instantanea.item() # atualização da perda\n","\n","        else:\n","          print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n","    print(\"\\nTempo de treino (em minutos) =\", (time()-inicio)/60)"],"metadata":{"id":"TTnsIdWugzMg","executionInfo":{"status":"aborted","timestamp":1755581383148,"user_tz":180,"elapsed":17,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Validando os resultados obtidos pelo modelo"],"metadata":{"id":"TkxmFRm76yrt"}},{"cell_type":"code","source":["def validacao(modelo, valloader, device):\n","    conta_corretas, conta_todas = 0, 0\n","    for imagens, etiquetas in valloader:\n","        for i in range(len(etiquetas)):\n","            img = imagens[i].view(1, 784)\n","            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n","            with torch.no_grad():\n","                logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n","\n","            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n","            probab = list(ps.cpu().numpy()[0])\n","            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo\n","            etiqueta_certa = etiquetas.numpy()[i]\n","            if(etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n","                conta_corretas += 1\n","            conta_todas += 1\n","\n","    print(\"\\nTotal de imagens testadas =\", conta_todas)\n","    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"],"metadata":{"id":"PqRtTyI0iFBf","executionInfo":{"status":"aborted","timestamp":1755581383152,"user_tz":180,"elapsed":6164,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definindo se o modelo vai usar o cuda \"GPU da Nvidia\" ou o CPU para processamento.\n","\n","### Nesse caso o Colab fornece o ambiente Cuda"],"metadata":{"id":"JLlQIwmc689Q"}},{"cell_type":"code","source":["modelo = Modelo()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","modelo.to(device)"],"metadata":{"id":"wG97s_6wi_OR","executionInfo":{"status":"aborted","timestamp":1755581383156,"user_tz":180,"elapsed":6164,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exibindo os resultados dos treinamentos por tempos e suas perdas por cada iteração"],"metadata":{"id":"4B4WQ_917VzN"}},{"cell_type":"code","metadata":{"id":"8e631e3d","executionInfo":{"status":"aborted","timestamp":1755581383159,"user_tz":180,"elapsed":6163,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["treino(modelo, trainloader, device)\n","validacao(modelo, valloader, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ff8842f"},"source":["# Exibindo os resultados de forma visual\n","# Task\n","\n","Visualize algumas previsões do modelo no conjunto de validação, exibindo a imagem, o rótulo previsto e o rótulo verdadeiro para alguns exemplos."]},{"cell_type":"markdown","metadata":{"id":"77f691d6"},"source":["## Obter um lote de dados\n","\n","### Subtask:\n","Obtenha um lote de imagens e rótulos do carregador de dados de validação."]},{"cell_type":"code","metadata":{"id":"346664ce","executionInfo":{"status":"aborted","timestamp":1755581383162,"user_tz":180,"elapsed":6165,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["dataiter_val = iter(valloader)\n","imagens_val, etiquetas_val = dataiter_val.__next__()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2d37e71"},"source":["## Fazer previsões\n","\n","### Subtask:\n","Passe as imagens pelo modelo treinado para obter as previsões do modelo.\n"]},{"cell_type":"code","metadata":{"id":"a47f2105","executionInfo":{"status":"aborted","timestamp":1755581383166,"user_tz":180,"elapsed":6168,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["imagens_val = imagens_val.view(imagens_val.shape[0], -1)\n","imagens_val = imagens_val.to(device)\n","with torch.no_grad():\n","    logps_val = modelo(imagens_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"845e7fab"},"source":["## Processar previsões\n","\n","### Subtask:\n","Converta a saída do modelo (probabilidades logarítmicas) em rótulos de classe previstos reais."]},{"cell_type":"code","metadata":{"id":"68971a42","executionInfo":{"status":"aborted","timestamp":1755581383202,"user_tz":180,"elapsed":6,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["ps_val = torch.exp(logps_val)\n","_, etiquetas_pred_val = torch.max(ps_val, dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c334e418"},"source":["## Visualizar resultados\n","\n","### Subtask:\n","Exiba algumas imagens do lote, mostrando a imagem em si, o rótulo previsto pelo modelo e o rótulo verdadeiro."]},{"cell_type":"code","metadata":{"id":"2f700eba","executionInfo":{"status":"aborted","timestamp":1755581383208,"user_tz":180,"elapsed":8,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["# Display a few predictions from the validation set\n","num_images_to_display = 5\n","\n","for i in range(min(num_images_to_display, len(etiquetas_val))):\n","    img = imagens_val[i].view(1, 28, 28)\n","    img = img.squeeze()\n","    plt.imshow(img.cpu().numpy(), cmap='gray_r')\n","    plt.title(f\"Predicted: {etiquetas_pred_val[i].item()}, True: {etiquetas_val[i].item()}\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ca2a033"},"source":["## Resumo:\n","\n","### Principais Descobertas da Análise de Dados\n","\n","* Um lote de imagens e rótulos foi obtido com sucesso do carregador de dados de validação.\n","* As imagens de validação foram processadas pelo modelo, resultando em probabilidades logarítmicas das classes previstas.\n","* As probabilidades logarítmicas foram convertidas em rótulos de classe previstos.\n","* As primeiras cinco imagens do lote foram visualizadas, cada uma exibindo a imagem, o rótulo previsto pelo modelo e o rótulo verdadeiro.\n","\n","### Insights ou Próximos Passos\n","\n","* A inspeção visual dos gráficos permite uma avaliação qualitativa do desempenho do modelo em exemplos individuais.\n","* Análises adicionais podem envolver a visualização de mais exemplos, incluindo aqueles em que o modelo fez previsões incorretas, para entender possíveis modos de falha."]},{"cell_type":"code","metadata":{"id":"2c2f8999","executionInfo":{"status":"aborted","timestamp":1755581383212,"user_tz":180,"elapsed":6,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["print(f\"O modelo usou {len(trainset)} imagens para treinamento.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6259443","executionInfo":{"status":"aborted","timestamp":1755581383217,"user_tz":180,"elapsed":2,"user":{"displayName":"Gabriel Luiz Senkovski","userId":"07176956522679885638"}}},"source":["print(f\"O modelo usou {len(valset)} imagens para validação/previsão.\")"],"execution_count":null,"outputs":[]}]}